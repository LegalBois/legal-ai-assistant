{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from operator import itemgetter\n",
    "from typing import List, Literal, Optional, Union\n",
    "\n",
    "import chromadb\n",
    "from dotenv import load_dotenv\n",
    "from IPython.display import Markdown\n",
    "from langchain_chroma import Chroma\n",
    "from langchain_core.prompts import ChatPromptTemplate, FewShotChatMessagePromptTemplate\n",
    "from langchain_core.runnables import RunnableLambda, Runnable\n",
    "from langchain_huggingface import HuggingFaceEmbeddings\n",
    "from langchain_mistralai.chat_models import ChatMistralAI\n",
    "from langsmith import traceable\n",
    "from pydantic import BaseModel, Field"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "load_dotenv()  # For MISTRAL_API_KEY and LangSmith tracing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "settings = {\n",
    "    \"llm\": {\"model_name\": \"mistral-large-latest\"},\n",
    "    \"emb_model\": {\"model_name\": \"deepvk/USER-bge-m3\"},\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load models\n",
    "llm = ChatMistralAI(**settings[\"llm\"])\n",
    "emb_model = HuggingFaceEmbeddings(**settings[\"emb_model\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Query classification and analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"prompts/system_prompt_1.txt\") as f:\n",
    "    system_prompt_1 = f.read()\n",
    "\n",
    "with open(\"prompts/examples_1.json\") as f:\n",
    "    examples_1 = json.load(f)\n",
    "\n",
    "example_prompt_1 = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"user\", \"{input}\"),\n",
    "        (\"assistant\", \"{output}\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "few_shot_prompt_1 = FewShotChatMessagePromptTemplate(\n",
    "    example_prompt=example_prompt_1,\n",
    "    examples=examples_1,\n",
    ")\n",
    "\n",
    "prompt_1 = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", system_prompt_1),\n",
    "        few_shot_prompt_1,\n",
    "        (\"user\", \"{question}\"),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RAGQueries(BaseModel):\n",
    "    \"\"\"\n",
    "    Данные, сформированные на основе запроса пользователя для поиска релевантных документов по юридической практике в векторной БД\n",
    "    Необходимы для уточнения запроса и повышения релевантности выдачи\n",
    "    \"\"\"\n",
    "\n",
    "    keyinfo: str = Field(description=\"Ключевая информация\")\n",
    "    rephrase: List[str] = Field(\n",
    "        description=\"Список из двух различных запросов в векторную базу данных, содержащую судебные дела\",\n",
    "    )\n",
    "    codex: Optional[\n",
    "        Literal[\"Гражданский кодекс\", \"Уголовный кодекс\", \"Административный кодекс\"]\n",
    "    ] = Field(\n",
    "        default=None,\n",
    "        description=\"Фильтр для уточнения правового поля запроса, используемый при обращении к векторной базе данных, если возможно определить\",\n",
    "    )\n",
    "\n",
    "\n",
    "class ChitChatResponse(BaseModel):\n",
    "    \"\"\"\n",
    "    Ответ на запрос пользователя, который не предполагает юридической консультации.\n",
    "    \"\"\"\n",
    "\n",
    "    response: str = Field(..., description=\"Ответ на общий или неюридический запрос пользователя.\")\n",
    "\n",
    "\n",
    "class FirstResponse(BaseModel):\n",
    "    \"\"\"\n",
    "    Итоговый результат обработки запроса пользователя.\n",
    "    В зависимости от характера запроса результат может быть представлен в двух форматах:\n",
    "    - RAGQueries: используется для юридических запросов. Содержит структурированные данные для обращения к векторной базе с целью поиска релевантных документов.\n",
    "    - ChitChatResponse: применяется для общих или неюридических запросов. Содержит текстовый ответ на запрос пользователя.\n",
    "    \"\"\"\n",
    "\n",
    "    response: Union[RAGQueries, ChitChatResponse] = Field(\n",
    "        ...,\n",
    "        description=\"\"\"Итоговый результат обработки запроса пользователя. \n",
    "    Форматы ответа:\n",
    "    - RAGQueries: для юридических запросов, содержит структурированные данные для поиска документов в векторной базе.\n",
    "    - ChitChatResponse: для общих запросов, содержит текстовый ответ.\"\"\",\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm_1 = llm.with_structured_output(FirstResponse)\n",
    "chain_1 = prompt_1 | llm_1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Retrieval and final generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "@traceable\n",
    "def create_queries(inputs: dict) -> dict:\n",
    "    \"\"\"\n",
    "    Creates 3 queries for retriever:\n",
    "        1. Original user query\n",
    "        2. Key info + query rephrase 1\n",
    "        3. Key info + query rephrase 2\n",
    "\n",
    "    Params:\n",
    "        `inputs` - output from previous LangChain Runnable in chain\n",
    "    \"\"\"\n",
    "    original_query: str = inputs[\"question\"]\n",
    "    llm_processed: RAGQueries = inputs[\"response_1\"].response\n",
    "    \n",
    "    queries = [original_query]\n",
    "    for s in llm_processed.rephrase:\n",
    "        queries.append(llm_processed.keyinfo + \"\\n\" + s)\n",
    "    return {\"queries\": queries, \"codex_filter\": llm_processed.codex}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up ChromaDB with legal practices docs\n",
    "# Note: this DB should already be initialized\n",
    "persistent_client = chromadb.PersistentClient(path=\"../legal_practice_db/vector_storage\")\n",
    "legal_practices_store = Chroma(\n",
    "    client=persistent_client,\n",
    "    collection_name=\"legal_practices\",\n",
    "    embedding_function=emb_model,\n",
    ")\n",
    "# Create retriever\n",
    "# Note: k = 3, because we pick the most relevant `unique` doc for each query (we have 3 queries)\n",
    "legal_practices_retriever = legal_practices_store.as_retriever(search_type=\"similarity\", search_kwargs={\"k\": 3})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "@traceable\n",
    "def batch_query(inputs: dict) -> dict:\n",
    "    \"\"\"\n",
    "    Makes batch invoke of retriever for each query. \n",
    "    Also set the filter for codex (if it's not None).\n",
    "\n",
    "    Params:\n",
    "        `inputs` - output from previous LangChain Runnable in chain\n",
    "    \"\"\"\n",
    "    # Add/remove codex filter for retriever\n",
    "    codex_poss_values = [\"А\", \"АГ\", \"АУ\", \"АГУ\", \"Г\", \"ГУ\", \"У\"]\n",
    "    if inputs[\"codex_filter\"] and inputs[\"codex_filter\"][0] in \"АГУ\":\n",
    "        legal_practices_retriever.search_kwargs[\"filter\"] = {\n",
    "            \"codex\": {\"$in\": [val for val in codex_poss_values if inputs[\"codex_filter\"][0] in val]}\n",
    "        }\n",
    "    else:\n",
    "        legal_practices_retriever.search_kwargs.pop(\"filter\", None)\n",
    "\n",
    "    # Batch retrieve\n",
    "    relevant_docs = legal_practices_retriever.batch(inputs[\"queries\"])\n",
    "\n",
    "    return {\"relevant_docs\": relevant_docs, \"orig_query\": inputs[\"queries\"][0]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "@traceable\n",
    "def prepare_docs(inputs) -> dict:\n",
    "    \"\"\"\n",
    "    Post-processing of retrieved relevant docs.\n",
    "    Steps:\n",
    "        1. Picks up the most relevant docs for each query w/o duplicates\n",
    "        2. Add `theme` from metadata of doc to its content\n",
    "        3. Merges all docs in one string\n",
    "\n",
    "    Params:\n",
    "        `inputs` - output from previous LangChain Runnable in chain\n",
    "    \"\"\"\n",
    "    relevant_docs = inputs[\"relevant_docs\"]\n",
    "    # Pick top document for each query without duplicates\n",
    "    seen_uids = set()\n",
    "    top_docs = []\n",
    "    for query_docs in relevant_docs:  # relevant_docs is a list of lists (docs per query)\n",
    "        for doc in query_docs:\n",
    "            uid: str = doc.metadata.get(\"uid\")\n",
    "            if uid not in seen_uids:\n",
    "                seen_uids.add(uid)\n",
    "                top_docs.append(doc)\n",
    "                break\n",
    "\n",
    "    # Merge `theme` into `page_content`\n",
    "    for doc in top_docs:\n",
    "        theme = doc.metadata.get(\"theme\", \"\")\n",
    "        doc.page_content = f\"{theme}\\n{doc.page_content}\"\n",
    "\n",
    "    # Merge all docs\n",
    "    context = \"\\n\\n\".join(doc.page_content for doc in top_docs)\n",
    "\n",
    "    return {\"context\": context, \"orig_query\": inputs[\"orig_query\"]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"prompts/system_prompt_2.txt\") as f:\n",
    "    system_prompt_2 = f.read()\n",
    "\n",
    "prompt_2 = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", system_prompt_2),\n",
    "        (\"user\", \"{orig_query}\\n===\\n{context}\"),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResponseWithLegalDocs(BaseModel):\n",
    "    \"\"\"\n",
    "    Модель для структурированного ответа с юридическими документами.\n",
    "    \"\"\"\n",
    "\n",
    "    text_response: str = Field(\n",
    "        description=\"Полный текст юридического ответа на запрос пользователя.\"\n",
    "    )\n",
    "    legal_docs: List[str] = Field(\n",
    "        description=\"Список названий юридических документов, использованных для формирования ответа.\",\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm_2 = llm.with_structured_output(ResponseWithLegalDocs)\n",
    "\n",
    "chain_2 = (\n",
    "    RunnableLambda(create_queries)\n",
    "    | RunnableLambda(batch_query)\n",
    "    | RunnableLambda(prepare_docs)\n",
    "    | prompt_2\n",
    "    | llm_2\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Final chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "@traceable\n",
    "def route(inputs) -> str | Runnable:\n",
    "    \"\"\"\n",
    "    Swithes behavior of pipeline based on query classification:\n",
    "        1. If LLM classify query as chit-chat - we just return the text response without doing RAG\n",
    "        2. Otherwise, if query belongs to legal field - execute `chain_2` for RAG\n",
    "\n",
    "    Params:\n",
    "        `inputs` - output from previous LangChain Runnable in chain\n",
    "    \"\"\"\n",
    "    if isinstance(inputs[\"response_1\"].response, ChitChatResponse):\n",
    "        return inputs[\"response_1\"].response.response\n",
    "    else:\n",
    "        return chain_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_chain = {\"response_1\": chain_1, \"question\": itemgetter(\"question\")} | RunnableLambda(route)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to use model_dump to serialize <class 'langchain_core.runnables.base.RunnableSequence'> to JSON: PydanticSerializationError(Unable to serialize unknown type: <class 'langchain_core.runnables.base.RunnableLambda'>)\n"
     ]
    }
   ],
   "source": [
    "query = \"Я ехал на велосипеде, упал и поцарапал машину, что делать и что мне будет?\"\n",
    "response = final_chain.invoke({\"question\": query})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "Если вы упали на велосипеде и поцарапали машину, ваши действия и последствия будут зависеть от нескольких факторов, включая обстоятельства происшествия, наличие свидетелей и степень ущерба.\n",
       "\n",
       "### Анализ запроса и контекста:\n",
       "\n",
       "Ваш случай относится к области гражданского права, регулируемого Гражданским кодексом Российской Федерации (ГК РФ). Основные положения, которые применимы к вашему случаю, включают:\n",
       "\n",
       "1. **Обязанность возмещения вреда** (ст. 1064 ГК РФ): Виновник причиненного вреда обязан его возместить. В вашем случае, если вы виновны в повреждении машины, вам придется возместить ущерб.\n",
       "\n",
       "2. **Предположение вины** (п. 2 ст. 1064 ГК РФ): Вина причинителя вреда предполагается, если не доказано иное. Это означает, что если вы не сможете доказать, что не виноваты, вам придется возместить ущерб.\n",
       "\n",
       "3. **Ответственность собственника транспортного средства** (ст. 1079 ГК РФ): В данном случае это положение не применимо, так как вы не являетесь собственником транспортного средства, которое было повреждено.\n",
       "\n",
       "### Основные шаги, которые вам следует предпринять:\n",
       "\n",
       "1. **Оценка ущерба**: Если владелец машины требует возмещения ущерба, вам может потребоваться проведение независимой оценки повреждений.\n",
       "\n",
       "2. **Переговоры с владельцем машины**: Попробуйте договориться с владельцем машины о размере возмещения ущерба. Если ущерб незначительный, возможно, удастся решить вопрос мирным путем.\n",
       "\n",
       "3. **Страхование**: Если у вас есть страховой полис, который покрывает такие случаи, свяжитесь со своей страховой компанией для получения консультации и возможного возмещения ущерба.\n",
       "\n",
       "4. **Судебное разбирательство**: Если мирное урегулирование невозможно, владелец машины может подать на вас в суд. В этом случае вам следует подготовиться к судебному разбирательству, собрав все доказательства, подтверждающие вашу позицию.\n",
       "\n",
       "### Рекомендации:\n",
       "\n",
       "- **Сохраните все доказательства**: Фотографии места происшествия, записи с камер видеонаблюдения, показания свидетелей и т.д.\n",
       "\n",
       "- **Консультация с юристом**: Если ситуация сложная, рекомендуется проконсультироваться с юристом, который поможет вам правильно оформить документы и подготовиться к судебному разбирательству.\n",
       "\n",
       "- **Сообщите о происшествии в полицию**: Это может помочь в дальнейшем, если дело дойдет до суда.\n",
       "\n",
       "### Ссылки на юридические документы:\n",
       "\n",
       "- Гражданский кодекс Российской Федерации (ст. 1064, 1079)\n",
       "- Федеральный закон от 25 апреля 2002 года №40-ФЗ «Об обязательном страховании гражданской ответственности владельцев транспортных средств»\n",
       "- Постановление Пленума Верховного Суда РФ от 26.01.2010 N 1 «О применении судами гражданского законодательства, регулирующего отношения по обязательствам вследствие причинения вреда жизни или здоровью гражданина»\n",
       "- Постановление Пленума Верховного Суда РФ от 23.06.2015 N 25 «О применении судами некоторых положений раздела I части первой Гражданского кодекса Российской Федерации»"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Markdown(response.text_response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Гражданский кодекс Российской Федерации (ст. 1064, 1079)',\n",
       " 'Федеральный закон от 25 апреля 2002 года №40-ФЗ «Об обязательном страховании гражданской ответственности владельцев транспортных средств»',\n",
       " 'Постановление Пленума Верховного Суда РФ от 26.01.2010 N 1 «О применении судами гражданского законодательства, регулирующего отношения по обязательствам вследствие причинения вреда жизни или здоровью гражданина»',\n",
       " 'Постановление Пленума Верховного Суда РФ от 23.06.2015 N 25 «О применении судами некоторых положений раздела I части первой Гражданского кодекса Российской Федерации»']"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response.legal_docs"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "practicing-rag",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
